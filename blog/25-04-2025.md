---
title: Vibe Coding
slug: vibe-coding
sidebar_position: 1
---

Vibe coding is gradually moving from weekend experiments to actual product development workflows. The more I see it used in real projects, the more obvious it becomes how rarely security is part of that conversation.

<!-- truncate -->

I’ve been vibe coding to develop parts of my projects, not the whole thing, but enough to see where it helps and where it introduces risk.

When you are in a flow where you are just asking for what you need (“add auth”, “fix this error”, “generate backend”), it’s easy to skip over the things that aren’t visible. You’re not thinking about how user input is sanitized, whether error handling is robust, or if sensitive routes are protected. You don’t always check how database queries are constructed, whether default settings expose ports or data, or what access controls are missing.

These are not things the LLM models will always surface, and they’re not things you’ll catch if you’re focused only on the immediate output. You get working code, but the deeper assumptions behind it — how it handles edge cases, what it trusts by default, or what gets logged can go unnoticed.

The issue isn’t that AI-generated code is always insecure. It’s that vibe coding workflows make it harder to notice when something is insecure. The more abstracted the process becomes, the more invisible those decisions are.

<iframe
    width="100%"
    height="500"
    src="https://www.reversinglabs.com/blog/vibe-coding-what-autonomous-code-means-for-appsec"
    title="Vibe coding: What automating development means for AppSec"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
</iframe>

